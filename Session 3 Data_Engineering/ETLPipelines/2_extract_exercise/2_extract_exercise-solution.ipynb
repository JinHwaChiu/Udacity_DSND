{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from JSON and XML\n",
    "\n",
    "You'll now get practice extracting data from JSON and XML. You'll extract the same population data from the previous exercise, except the data will be in a different format.\n",
    "\n",
    "Both JSON and XML are common formats for storing data. XML was established before JSON, and JSON has become more popular over time. They both tend to be used for sending data via web APIs, which you'll learn about later in the lesson.\n",
    "\n",
    "Sometimes, you can obtain the same data in either JSON or XML format. That is the case for this exercise. You'll use the same data except one file is formatted as JSON and the other as XML.\n",
    "\n",
    "There is a solution file for these exercises. Go to File->Open and click on 2_extract_exercise_solution.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract JSON and JSON Exercise\n",
    "\n",
    "First, you'll practice extracting data from a JSON file. Run the cell below to print out the first line of the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "#   Run the following cell.\n",
    "#   This cell loads a function that prints the first n lines of\n",
    "#   a file.\n",
    "#\n",
    "#   Then this function is called on the JSON file to print out\n",
    "#   the first line of the population_data.json file\n",
    "###\n",
    "\n",
    "def print_lines(n, file_name):\n",
    "    f = open(file_name)\n",
    "    for i in range(n):\n",
    "        print(f.readline())\n",
    "    f.close()\n",
    "    \n",
    "print_lines(1, 'population_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first \"line\" in the file is actually the entire file. JSON is a compact way of representing data in a dictionary-like format. Luckily, pandas has a method to [read in a json file](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html). \n",
    "\n",
    "If you open the link with the documentation, you'll see there is an *orient* option that can handle JSON formatted in different ways:\n",
    "```\n",
    "'split' : dict like {index -> [index], columns -> [columns], data -> [values]}\n",
    "'records' : list like [{column -> value}, ... , {column -> value}]\n",
    "'index' : dict like {index -> {column -> value}}\n",
    "'columns' : dict like {column -> {index -> value}}\n",
    "'values' : just the values array\n",
    "```\n",
    "\n",
    "In this case, the JSON is formatted with a 'records' orientation, so you'll need to use that value in the read_json() method. You can tell that the format is 'records' by comparing the pattern in the documentation with the pattern in the JSON file.\n",
    "\n",
    "Next, read in the population_data.json file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Read in the population_data.json file using pandas's \n",
    "# read_json method. Don't forget to specific the orient option\n",
    "# store the rsults in df_json\n",
    "\n",
    "import pandas as pd\n",
    "df_json = pd.read_json('population_data.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the head method to see the first few rows of the resulting\n",
    "# dataframe\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this population data is the same as the data from the previous exercise. The column order might have changed, but the data is otherwise the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Ways to Read in JSON\n",
    "\n",
    "Besides using pandas to read JSON files, you can use the json library. Run the code cell below to see an example of reading in JSON with the json library. Python treats JSON data like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read in the JSON file\n",
    "with open('population_data.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# print the first record in the JSON file\n",
    "print(json_data[0])\n",
    "print('\\n')\n",
    "\n",
    "# show that JSON data is essentially a dictionary\n",
    "print(json_data[0]['Country Name'])\n",
    "print(json_data[0]['Country Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract XML\n",
    "\n",
    "Next, you'll work with the same data except now the data is in xml format. Run the next code cell to see what the first fifteen lines of the data file look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lines(15, 'population_data.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML looks very similar to HTML. XML is formatted with tags with values inside the tags. XML is not as easy to navigate as JSON. Pandas cannot read in XML directly. One reason is that tag names are user defined. Every XML file might have different formatting. You can imagine why XML has fallen out of favor relative to JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read and navigate XML\n",
    "\n",
    "There is a Python library called BeautifulSoup, which makes reading in and parsing XML data easier. Here is the link to the documentation: [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/)\n",
    "\n",
    "The find() method will find the first place where an xml element occurs. For example using find('record') will return the first record in the xml file:\n",
    "\n",
    "```xml\n",
    "<record>\n",
    "  <field name=\"Country or Area\" key=\"ABW\">Aruba</field>\n",
    "  <field name=\"Item\" key=\"SP.POP.TOTL\">Population, total</field>\n",
    "  <field name=\"Year\">1960</field>\n",
    "  <field name=\"Value\">54211</field>\n",
    "</record>\n",
    "```\n",
    "\n",
    "The find_all() method returns all of the matching tags. So find_all('record') would return all of the elements with the `<record>` tag.\n",
    "\n",
    "Run the code cells below to get a basic idea of how to navigate XML with BeautifulSoup. To navigate through the xml file, you search for a specific tag using the find() method or find_all() method. \n",
    "\n",
    "Below these code cells, there is an exercise for wrangling the XML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp950' codec can't decode byte 0xbf in position 2: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# open the population_data.xml file and load into Beautiful Soup\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation_data.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m----> 6\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:312\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;241m=\u001b[39m parse_only\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[43mmarkup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    314\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp950' codec can't decode byte 0xbf in position 2: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# import the BeautifulSoup library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# open the population_data.xml file and load into Beautiful Soup\n",
    "with open(\"population_data.xml\") as fp:\n",
    "    soup = BeautifulSoup(fp, \"lxml\") # lxml is the Parser type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# use the find_all method to get all record tags in the document\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m \u001b[43msoup\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# use the find_all method to get all fields in each record\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# output the first 5 records in the xml file\n",
    "# this is an example of how to navigate with BeautifulSoup\n",
    "\n",
    "i = 0\n",
    "# use the find_all method to get all record tags in the document\n",
    "for record in soup.find_all('record'):\n",
    "    # use the find_all method to get all fields in each record\n",
    "    i += 1\n",
    "    for record in record.find_all('field'):\n",
    "        print(record['name'], ': ' , record.text)\n",
    "    print()\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Exercise (Challenge)\n",
    "\n",
    "Create a data frame from the xml file. This exercise is somewhat tricky. One solution would be to convert the xml data into dictionaries and then use the dictionaries to create a data frame. \n",
    "\n",
    "The dataframe should have the following layout:\n",
    "\n",
    "| Country or Area | Year | Item | Value |\n",
    "|----|----|----|----|\n",
    "| Aruba | 1960 | Population, total | 54211 |\n",
    "| Aruba | 1961 | Population, total | 55348 |\n",
    "etc...\n",
    "\n",
    "Technically, extracting XML, transforming the results, and putting it into a data frame is a full ETL pipeline. This exercise is jumping ahead in terms of what's to come later in the lesson. But it's a good chance to familiarize yourself with XML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Create a pandas data frame from the XML data.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# HINT: You can use dictionaries to create pandas data frames.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# HINT: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# use the find_all method to get all record tags in the document\u001b[39;00m\n\u001b[0;32m     12\u001b[0m data_dictionary \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry or Area\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItem\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m \u001b[43msoup\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m         data_dictionary[record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mappend(record\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create a pandas data frame from the XML data.\n",
    "# HINT: You can use dictionaries to create pandas data frames.\n",
    "# HINT: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict\n",
    "# HINT: You can make a dictionary for each column or for each row\n",
    "# HINT: Modify the code from the previous code cell\n",
    "\n",
    "\n",
    "# output the first 5 records in the xml file\n",
    "# this is an example of how to navigate with BeautifulSoup\n",
    "\n",
    "# use the find_all method to get all record tags in the document\n",
    "data_dictionary = {'Country or Area':[], 'Year':[], 'Item':[], 'Value':[]}\n",
    "\n",
    "for record in soup.find_all('record'):\n",
    "    for record in record.find_all('field'):\n",
    "        data_dictionary[record['name']].append(record.text)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dictionary)\n",
    "df = df.pivot(index='Country or Area', columns='Year', values='Value')\n",
    "df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Like CSV, JSON and XML are ways to format data. If everything is formatted correctly, JSON is especially easy to work with. XML is an older standard and a bit trickier to handle.\n",
    "\n",
    "As a reminder, there is a solution file for these exercises. You can go to File->Open and then click on 2_extract_exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
